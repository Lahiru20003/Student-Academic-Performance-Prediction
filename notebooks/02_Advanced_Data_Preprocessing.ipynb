{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e172a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_Advanced_Data_Preprocessing.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe1ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/StudentsPerformance.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d71d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Engineering: Create a new target variable\n",
    "df['average score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(['math score', 'reading score', 'writing score', 'average score'], axis=1)\n",
    "y = df['average score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a76df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Advanced Preprocessing with Scikit-learn Pipelines\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "\n",
    "# Create a preprocessor pipeline\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd0f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ColumnTransformer to apply the preprocessor to only the categorical columns\n",
    "full_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical_preprocessing', preprocessor, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e00a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_processed = full_pipeline.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280c6c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Preprocessed data and pipeline saved.\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0        1.0        0.0        0.0        1.0        0.0        0.0   \n",
      "1        1.0        0.0        0.0        0.0        1.0        0.0   \n",
      "2        1.0        0.0        0.0        1.0        0.0        0.0   \n",
      "3        0.0        1.0        1.0        0.0        0.0        0.0   \n",
      "4        0.0        1.0        0.0        0.0        1.0        0.0   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0        0.0        0.0        1.0        0.0         0.0         0.0   \n",
      "1        0.0        0.0        0.0        0.0         0.0         1.0   \n",
      "2        0.0        0.0        0.0        0.0         1.0         0.0   \n",
      "3        0.0        1.0        0.0        0.0         0.0         0.0   \n",
      "4        0.0        0.0        0.0        0.0         0.0         1.0   \n",
      "\n",
      "   feature_12  feature_13  feature_14  feature_15  feature_16  average_score  \n",
      "0         0.0         0.0         1.0         0.0         1.0      72.666667  \n",
      "1         0.0         0.0         1.0         1.0         0.0      82.333333  \n",
      "2         0.0         0.0         1.0         0.0         1.0      92.666667  \n",
      "3         0.0         1.0         0.0         0.0         1.0      49.333333  \n",
      "4         0.0         0.0         1.0         0.0         1.0      76.333333  \n"
     ]
    }
   ],
   "source": [
    "# 3. Create a final DataFrame and save it\n",
    "# We can't use get_feature_names_out() directly because of the remainder='passthrough'.\n",
    "# The easiest way to get the correct number of columns is to use the transformed data's shape.\n",
    "num_features = X_processed.shape[1]\n",
    "processed_df = pd.DataFrame(X_processed.toarray(), columns=[f'feature_{i}' for i in range(num_features)])\n",
    "processed_df['average_score'] = y\n",
    "\n",
    "# Save the preprocessed data and the pipeline for later use\n",
    "processed_df.to_csv('../data/preprocessed_data.csv', index=False)\n",
    "joblib.dump(full_pipeline, '../models/preprocessor_pipeline.pkl')\n",
    "\n",
    "print(\"Data preprocessing complete. Preprocessed data and pipeline saved.\")\n",
    "print(processed_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Student-Academic-Performance-Prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
